{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset\n",
    "\n",
    "Used to create the three split sets: train, test and validation, dividing the classes equally for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the percentage of the data used for each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.65\n",
    "valid_size = 0.25\n",
    "test_size  = 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data from the dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset/\"\n",
    "\n",
    "loader, classes = utils.load_data(dataset_path + \"all/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a matrix with the images of each class separated\n",
    "\n",
    "The lines of the array represent a class and have all the images from that class. Example below:\n",
    "\n",
    "images_class_matrix[0] -> img1, img2, img3  \n",
    "images_class_matrix[1] -> img1  \n",
    "images_class_matrix[2] -> img1, img2  \n",
    ".  \n",
    ".  \n",
    "images_class_matrix[6] -> img1, img2, img4, img6\n",
    "  \n",
    "   \n",
    "Where the indexes represent the following classes:  \n",
    "0 -> bicycle  \n",
    "1 -> bus  \n",
    "2 -> car  \n",
    ".  \n",
    ".  \n",
    "6 -> van"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigoamf/anaconda3/envs/vehicle-classification/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:802: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 5.26 s, total: 1min 7s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "images_class_matrix = []\n",
    "train_images = []\n",
    "test_images  = []\n",
    "valid_images = []\n",
    "for i in range(len(classes)):\n",
    "    images_class_matrix.append([])\n",
    "    train_images.append([])\n",
    "    test_images.append([])\n",
    "    valid_images.append([])\n",
    "\n",
    "data_iterator = iter(loader)\n",
    "    \n",
    "for image, label in data_iterator:\n",
    "    image, label = np.array(image).squeeze().transpose(1,2,0), np.array(label).squeeze()\n",
    "    images_class_matrix[label].append(image)\n",
    "images_class_matrix = np.array(images_class_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the images to the splits sets using *images_class_matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_index, class_images in enumerate(images_class_matrix):\n",
    "    len_class_images = len(class_images)\n",
    "    indices = list(range(len_class_images))\n",
    "    split1 = int(np.floor(valid_size * len_class_images)) # end validation\n",
    "    split2 = int(np.floor((valid_size * len_class_images) + (test_size * len_class_images))) # end test\n",
    "    \n",
    "    valid_idx, test_idx, train_idx = indices[:split1], indices[split1:split2], indices[split2:len_class_images]\n",
    "    for index in train_idx:\n",
    "        train_images[class_index].append(class_images[index])\n",
    "    for index in valid_idx:\n",
    "        valid_images[class_index].append(class_images[index])\n",
    "    for index in test_idx:\n",
    "        test_images[class_index].append(class_images[index])\n",
    "train_images = np.array(train_images)\n",
    "test_images = np.array(test_images)\n",
    "valid_images = np.array(valid_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count how much images do we have in each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1086 images for training\n",
      "414  images for validation\n",
      "164  images for test\n",
      "Total of 1664 images\n"
     ]
    }
   ],
   "source": [
    "counter_train = list(0 for i in range(len(train_images)))\n",
    "counter_test = list(0 for i in range(len(test_images)))\n",
    "counter_valid = list(0 for i in range(len(valid_images)))\n",
    "\n",
    "for index in range(len(train_images)):\n",
    "    counter_train[index] = len(train_images[index])\n",
    "for index in range(len(test_images)):\n",
    "    counter_test[index] = len(test_images[index])\n",
    "for index in range(len(valid_images)):\n",
    "    counter_valid[index] = len(valid_images[index])\n",
    "    \n",
    "counter_train = np.array(counter_train)\n",
    "counter_valid = np.array(counter_valid)\n",
    "counter_test = np.array(counter_test)\n",
    "counter_total = counter_train.sum() + counter_valid.sum() + counter_test.sum()\n",
    "\n",
    "print(\"%-4s images for training\" % str(counter_train.sum()))\n",
    "print(\"%-4s images for validation\" % str(counter_valid.sum()))\n",
    "print(\"%-4s images for test\" % str(counter_test.sum()))\n",
    "print(\"Total of %s images\" % str(counter_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the images to their folders inside the dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [train_images, valid_images, test_images]\n",
    "split_names = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "for split_index, split in enumerate(splits):\n",
    "    directory = dataset_path + split_names[split_index] + \"/\"\n",
    "    for class_index, class_images in enumerate(split):\n",
    "        directory_class = directory + classes[class_index] + \"/\"\n",
    "        utils.create_directory(directory_class)\n",
    "        counter_class = 0\n",
    "        for image in class_images:\n",
    "            image_name = classes[class_index] + \"_\" + str(counter_class)\n",
    "            image_path = directory_class + image_name\n",
    "\n",
    "            utils.save_image(image_path, image)\n",
    "\n",
    "            counter_class += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vehicle-classification] *",
   "language": "python",
   "name": "conda-env-vehicle-classification-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
